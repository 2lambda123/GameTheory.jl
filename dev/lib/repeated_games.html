<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Repeated Games · Games.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Games.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><span class="toctext">Library</span><ul><li><a class="toctext" href="base_types_and_methods.html">Base Types and Methods</a></li><li><a class="toctext" href="game_generators.html">Game Generators</a></li><li><a class="toctext" href="computing_nash_equilibria.html">Computing Nash Equilibria</a></li><li class="current"><a class="toctext" href="repeated_games.html">Repeated Games</a><ul class="internal"><li><a class="toctext" href="#Exported-1">Exported</a></li><li><a class="toctext" href="#Internal-1">Internal</a></li></ul></li><li><a class="toctext" href="index.html">Index</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Library</li><li><a href="repeated_games.html">Repeated Games</a></li></ul><a class="edit-page" href="https://github.com/QuantEcon/Games.jl/blob/master/docs/src/lib/repeated_games.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Repeated Games</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="repeated_games-1" href="#repeated_games-1">Repeated Games</a></h1><h2><a class="nav-anchor" id="Exported-1" href="#Exported-1">Exported</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.RepeatedGame" href="#Games.RepeatedGame"><code>Games.RepeatedGame</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">RepeatedGame{N,T}</code></pre><p>Type representing an N-player repeated game.</p><p><strong>Fields</strong></p><ul><li><code>sg::NormalFormGame{N, T}</code> : The stage game used to create the repeated game.</li><li><code>delta::Float64</code> : The common discount rate at which all players discount the future.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L10-L20">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.RepeatedGame-Tuple{Player,Player,Float64}" href="#Games.RepeatedGame-Tuple{Player,Player,Float64}"><code>Games.RepeatedGame</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">RepeatedGame(p1, p2, delta)</code></pre><p>Helper constructor that builds a repeated game for two players.</p><p><strong>Arguments</strong></p><ul><li><code>p1::Player</code> : The first player.</li><li><code>p2::Player</code> : The second player.</li><li><code>delta::Float64</code> : The common discount rate at which all players discount the future.</li></ul><p><strong>Returns</strong></p><ul><li><code>::RepeatedGame</code> : The repeated game.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L38-L53">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.outerapproximation-Union{Tuple{RepeatedGame{2,T} where T&lt;:Real}, Tuple{TO}} where TO&lt;:MathOptInterface.AbstractOptimizer" href="#Games.outerapproximation-Union{Tuple{RepeatedGame{2,T} where T&lt;:Real}, Tuple{TO}} where TO&lt;:MathOptInterface.AbstractOptimizer"><code>Games.outerapproximation</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">outerapproximation(rpd; nH=32, tol=1e-8, maxiter=500, check_pure_nash=true,
                   verbose=false, nskipprint=50,
                   plib=default_library(2, Float64),
                   lp_solver=() -&gt; Clp.Optimizer(LogLevel=0))</code></pre><p>Approximates the set of equilibrium values for a repeated game with the outer hyperplane approximation described by Judd, Yeltekin, Conklin (2002).</p><p><strong>Arguments</strong></p><ul><li><code>rpd::RepGame2</code> : Two player repeated game.</li><li><code>nH::Int</code> : Number of subgradients used for the approximation.</li><li><code>tol::Float64</code> : Tolerance in differences of set.</li><li><code>maxiter::Int</code> : Maximum number of iterations.</li><li><code>check_pure_nash</code>: Whether to perform a check about whether a pure Nash equilibrium exists.</li><li><code>verbose::Bool</code> : Whether to display updates about iterations and distance.</li><li><code>nskipprint::Int</code> : Number of iterations between printing information (assuming verbose=true).</li><li><code>plib::Polyhedra.Library</code>: Allows users to choose a particular package for the geometry computations. (See <a href="https://github.com/JuliaPolyhedra/Polyhedra.jl">Polyhedra.jl</a> docs for more info). By default, it chooses to use <code>Polyhedra.DefaultLibrary</code>.</li><li><code>lp_solver::Union{&lt;:Type{MathOptInterface.AbstractOptimizer},Function}</code> : Linear programming solver to be used internally. Pass a <code>MathOptInterface.AbstractOptimizer</code> type (such as <code>Clp.Optimizer</code>) if no option is needed, or a function (such as <code>() -&gt; Clp.Optimizer(LogLevel=0)</code>) to supply options.</li></ul><p><strong>Returns</strong></p><ul><li><code>vertices::Matrix{Float64}</code> : Vertices of the outer approximation of the value set.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L330-L364">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.unpack-Tuple{RepeatedGame}" href="#Games.unpack-Tuple{RepeatedGame}"><code>Games.unpack</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">unpack(rpd)</code></pre><p>Helper function that unpacks the elements of a repeated game.</p><p><strong>Arguments</strong></p><ul><li><code>rpd::RepeatedGame</code> : The repeated game.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Tuple{NormalFormGame, Float64}</code> : A tuple containing the stage game and the delta.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L57-L70">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.worst_value_1-Union{Tuple{TO}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1}}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Union{Function, Type{TO}}}} where TO&lt;:MathOptInterface.AbstractOptimizer" href="#Games.worst_value_1-Union{Tuple{TO}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1}}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Union{Function, Type{TO}}}} where TO&lt;:MathOptInterface.AbstractOptimizer"><code>Games.worst_value_1</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>See <code>worst_value_i</code> for documentation</p></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L311">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.worst_value_2-Union{Tuple{TO}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1}}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Union{Function, Type{TO}}}} where TO&lt;:MathOptInterface.AbstractOptimizer" href="#Games.worst_value_2-Union{Tuple{TO}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1}}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Union{Function, Type{TO}}}} where TO&lt;:MathOptInterface.AbstractOptimizer"><code>Games.worst_value_2</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>See <code>worst_value_i</code> for documentation</p></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L319">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.worst_value_i-Union{Tuple{TO}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Int64}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Int64,Union{Function, Type{TO}}}} where TO&lt;:MathOptInterface.AbstractOptimizer" href="#Games.worst_value_i-Union{Tuple{TO}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Int64}, Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2},Array{Float64,1},Int64,Union{Function, Type{TO}}}} where TO&lt;:MathOptInterface.AbstractOptimizer"><code>Games.worst_value_i</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">worst_value_i(rpd, H, C, i)</code></pre><p>Given a constraint w ∈ W, this finds the worst possible payoff for agent i.</p><p><strong>Arguments</strong></p><ul><li><code>rpd::RepGame2</code> : Two player repeated game.</li><li><code>H::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the subgradients here <code>nH</code> is the number of subgradients.</li><li><code>C::Vector{Float64}</code> : The array containing the hyperplane levels.</li><li><code>i::Int</code> : The player of interest.</li><li><code>lp_solver::Union{Type{&lt;:MathOptInterface.AbstractOptimizer},Function}</code> : Linear programming solver to be used internally. Pass a  <code>MathOptInterface.AbstractOptimizer</code> type (such as <code>Clp.Optimizer</code>) if no option is needed, or a function (such as <code>() -&gt; Clp.Optimizer(LogLevel=0)</code>) to supply options.</li></ul><p><strong>Returns</strong></p><ul><li><code>out::Float64</code> : Worst possible payoff for player i.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L243-L265">source</a></section><h2><a class="nav-anchor" id="Internal-1" href="#Internal-1">Internal</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.RepGame2" href="#Games.RepGame2"><code>Games.RepGame2</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">RepGame2</code></pre><p>Type representing a 2-player repeated game; alias for <code>RepeatedGame{2}</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L27-L31">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.initialize_LP_matrices-Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2}}" href="#Games.initialize_LP_matrices-Tuple{RepeatedGame{2,T} where T&lt;:Real,Array{Float64,2}}"><code>Games.initialize_LP_matrices</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">initialize_LP_matrices(rpd, H)</code></pre><p>Initialize matrices for the linear programming problems.</p><p><strong>Arguments</strong></p><ul><li><code>rpd::RepeatedGame</code> : Two player repeated game.</li><li><code>H::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the subgradients used to approximate the value set, where <code>nH</code> is the number of subgradients.</li></ul><p><strong>Returns</strong></p><ul><li><code>c::Vector{Float64}</code> : Vector of length <code>nH</code> used to determine which subgradient should be used, where <code>nH</code> is the number of subgradients.</li><li><code>A::Matrix{Float64}</code> : Matrix of shape <code>(nH+2, 2)</code> with nH set constraints and to be filled with 2 additional incentive compatibility constraints.</li><li><code>b::Vector{Float64}</code> : Vector of length <code>nH+2</code> to be filled with the values for the constraints.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L202-L221">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.initialize_sg_hpl-Tuple{Int64,Array{Float64,1},Float64}" href="#Games.initialize_sg_hpl-Tuple{Int64,Array{Float64,1},Float64}"><code>Games.initialize_sg_hpl</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">initialize_sg_hpl(nH, o, r)</code></pre><p>Initializes subgradients, extreme points and hyperplane levels for the approximation of the convex value set of a 2 player repeated game.</p><p><strong>Arguments</strong></p><ul><li><code>nH::Int</code> : Number of subgradients used for the approximation.</li><li><code>o::Vector{Float64}</code> : Origin for the approximation.</li><li><code>r::Float64</code> : Radius for the approximation.</li></ul><p><strong>Returns</strong></p><ul><li><code>C::Vector{Float64}</code> : Vector of length <code>nH</code> containing the hyperplane levels.</li><li><code>H::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the subgradients.</li><li><code>Z::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the extreme points of the value set.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L126-L145">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.initialize_sg_hpl-Tuple{RepeatedGame,Int64}" href="#Games.initialize_sg_hpl-Tuple{RepeatedGame,Int64}"><code>Games.initialize_sg_hpl</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">initialize_sg_hpl(rpd, nH)</code></pre><p>Initializes subgradients, extreme points and hyperplane levels for the approximation of the convex value set of a 2 player repeated game by choosing an appropriate origin and radius.</p><p><strong>Arguments</strong></p><ul><li><code>rpd::RepeatedGame</code> : Two player repeated game.</li><li><code>nH::Int</code> : Number of subgradients used for the approximation.</li></ul><p><strong>Returns</strong></p><ul><li><code>C::Vector{Float64}</code> : Vector of length <code>nH</code> containing the hyperplane levels.</li><li><code>H::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the subgradients.</li><li><code>Z::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the extreme points of the value set.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L166-L185">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Games.unitcircle-Tuple{Int64}" href="#Games.unitcircle-Tuple{Int64}"><code>Games.unitcircle</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">unitcircle(npts)</code></pre><p>Places <code>npts</code> equally spaced points along the 2 dimensional unit circle and returns the points with x coordinates in first column and y coordinates in second column.</p><p><strong>Arguments</strong></p><ul><li><code>npts::Int</code> : Number of points to be placed.</li></ul><p><strong>Returns</strong></p><ul><li><code>pts::Matrix{Float64}</code> : Matrix of shape <code>(nH, 2)</code> containing the coordinates of the points.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/QuantEcon/Games.jl/blob/f3c8ab36c8b700252c60fd32cc458fa388398885/src/repeated_game.jl#L95-L110">source</a></section><footer><hr/><a class="previous" href="computing_nash_equilibria.html"><span class="direction">Previous</span><span class="title">Computing Nash Equilibria</span></a><a class="next" href="index.html"><span class="direction">Next</span><span class="title">Index</span></a></footer></article></body></html>
